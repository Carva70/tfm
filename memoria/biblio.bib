% Insertar bibliografía aquí en formato bibTeX

@article{gulyamov2026promptinjection,
	author  = {Gulyamov, Saidakhror and Gulyamov, Said and Rodionov, Andrey and Khursanov, Rustam and Mekhmonov, Kambariddin and Babaev, Djakhongir and Rakhimjonov, Akmaljon},
	title   = {Prompt Injection Attacks in Large Language Models and AI Agent Systems: A Comprehensive Review of Vulnerabilities, Attack Vectors, and Defense Mechanisms},
	journal = {Information},
	year    = {2026},
	volume  = {17},
	number  = {54},
	doi     = {10.3390/info17010054},
	url     = {https://doi.org/10.3390/info17010054}
}

@online{openai_platform,
	author = {{OpenAI}},
	title  = {OpenAI API Platform},
	year   = {2026},
	url    = {https://platform.openai.com/},
	note   = {Accedido: 2026-01-26}
}

@online{meta_llama,
	author = {{Meta AI}},
	title  = {Llama},
	year   = {2026},
	url    = {https://ai.meta.com/llama/},
	note   = {Accedido: 2026-01-26}
}

@online{langchain,
	author = {{LangChain}},
	title  = {LangChain Documentation},
	year   = {2026},
	url    = {https://python.langchain.com/},
	note   = {Accedido: 2026-01-26}
}

@article{greshake2023indirectpromptinjection,
	author  = {Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
	title   = {Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection},
	journal = {arXiv},
	year    = {2023},
	volume  = {abs/2302.12173},
	url     = {https://arxiv.org/abs/2302.12173}
}

@article{benjamin2024systematically,
	author  = {Benjamin, Victoria and Braca, Emily and Carter, Israel and Kanchwala, Hafsa and Khojasteh, Nava and Landow, Charly and Luo, Yi and Ma, Caroline and Magarelli, Anna and Mirin, Rachel and Moyer, Avery and Simpson, Kayla and Skawinski, Amelia and Heverin, Thomas},
	title   = {Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures},
	journal = {arXiv},
	year    = {2024},
	volume  = {abs/2410.23308},
	url     = {https://arxiv.org/abs/2410.23308}
}

@online{openai_safeguards,
	author = {{OpenAI}},
	title  = {User guide for gpt-oss-safeguard},
	year   = {2025},
	url    = {https://cookbook.openai.com/articles/gpt-oss-safeguard-guide},
	note   = {Accedido: 2026-01-31}
}

@online{ibm_llm_security,
	author = {{IBM}},
	title  = {What are large language models (LLMs)?},
	year   = {},
	url    = {https://www.ibm.com/think/topics/large-language-models},
	note   = {Accedido: 2026-01-31}
}

@online{nist_ai_rmf,
	author = {{NIST}},
	title  = {AI Risk Management Framework (AI RMF 1.0)},
	year   = {2023},
	url    = {https://www.nist.gov/itl/ai-risk-management-framework},
	note   = {Accedido: 2026-02-10}
}

@online{eu_ai_act,
	author = {{European Union}},
	title  = {EU Artificial Intelligence Act (AI Act)},
	year   = {2025},
	url    = {https://artificialintelligenceact.eu/es/},
	note   = {Accedido: 2026-02-10}
}

@online{mitre_atlas,
	author = {{MITRE}},
	title  = {Adversarial Threat Landscape for Artificial-Intelligence Systems (ATLAS)},
	year   = {2024},
	url    = {https://atlas.mitre.org/},
	note   = {Accedido: 2026-02-10}
}

@article{vaswani2017attention,
	author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	title   = {Attention Is All You Need},
	journal = {arXiv},
	year    = {2017},
	volume  = {abs/1706.03762},
	url     = {https://arxiv.org/abs/1706.03762}
}

@article{devlin2018bert,
	author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	title   = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	journal = {arXiv},
	year    = {2018},
	volume  = {abs/1810.04805},
	url     = {https://arxiv.org/abs/1810.04805}
}

@article{brown2020gpt3,
	author  = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	title   = {Language Models are Few-Shot Learners},
	journal = {arXiv},
	year    = {2020},
	volume  = {abs/2005.14165},
	url     = {https://arxiv.org/abs/2005.14165}
}

@article{ouyang2022instructgpt,
	author  = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F. and Leike, Jan and Lowe, Ryan},
	title   = {Training Language Models to Follow Instructions with Human Feedback},
	journal = {arXiv},
	year    = {2022},
	volume  = {abs/2203.02155},
	url     = {https://arxiv.org/abs/2203.02155}
}

@online{owasp_llmtop10,
	author = {{OWASP}},
	title  = {OWASP Top 10 for Large Language Model Applications 2025},
	year   = {2025},
	url    = {https://genai.owasp.org/llm-top-10/},
	note   = {Accedido: 2026-02-13}
}

@article{debi2026wealth,
	author  = {Debi, Tanusree and Zhu, Wentian},
	title   = {Whispers of Wealth: Red-Teaming Google's Agent Payments Protocol via Prompt Injection},
	journal = {arXiv},
	year    = {2026},
	volume  = {abs/2601.22569},
	url     = {https://arxiv.org/abs/2601.22569}
}

@article{lee2026mpib,
	author  = {Lee, Junhyeok and Jang, Han and Choi, Kyu Sung},
	title   = {MPIB: A Benchmark for Medical Prompt Injection Attacks and Clinical Safety in LLMs},
	journal = {arXiv},
	year    = {2026},
	volume  = {abs/2602.06268},
	url     = {https://arxiv.org/abs/2602.06268}
}

@article{maloyan2026mcp,
	author  = {Maloyan, Narek and Namiot, Dmitry},
	title   = {Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents},
	journal = {arXiv},
	year    = {2026},
	volume  = {abs/2601.17549},
	url     = {https://arxiv.org/abs/2601.17549}
}

@article{koide2026clouding,
	author  = {Koide, Takashi and Nakano, Hiroki and Chiba, Daiki},
	title   = {Clouding the Mirror: Stealthy Prompt Injection Attacks Targeting LLM-based Phishing Detection},
	journal = {arXiv},
	year    = {2026},
	volume  = {abs/2602.05484},
	url     = {https://arxiv.org/abs/2602.05484}
}

@article{chen2026learning,
	author  = {Chen, Xin and Zhang, Jie and Tramer, Florian},
	title   = {Learning to Inject: Automated Prompt Injection via Reinforcement Learning},
	journal = {arXiv},
	year    = {2026},
	volume  = {abs/2602.05746},
	url     = {https://arxiv.org/abs/2602.05746}
}

@article{rahman2026bypassing,
	author  = {Rahman, Md Jahedur and Alouani, Ihsen},
	title   = {Bypassing Prompt Injection Detectors through Evasive Injections},
	journal = {arXiv},
	year    = {2026},
	volume  = {abs/2602.00750},
	url     = {https://arxiv.org/abs/2602.00750}
}